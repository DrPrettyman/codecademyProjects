{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e471b00",
   "metadata": {},
   "source": [
    "###### TERM FREQUENCY–INVERSE DOCUMENT FREQUENCY (tf-idf)\n",
    "# Introduction\n",
    "\n",
    "It’s a dark night in the middle of winter as you make your way through another of Emily Dickinson’s poems. As you grapple with questions of immortality and death, you notice the word choice in each poem you read. With each passing poem, you discover for yourself which words are common throughout her work, and which indicate more unique meaning in individual poems.\n",
    "\n",
    "You might not even realize, but you are building a language model in your head similar to term frequency-inverse document frequency, commonly known as tf-idf. Tf-idf is another powerful tool in your NLP toolkit that has a variety of use cases included:\n",
    "\n",
    "- ranking results in a search engine\n",
    "- text summarization\n",
    "- building smarter chatbots\n",
    "\n",
    "See also the [Scikit-Learn site](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#from-occurrences-to-frequencies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a2ba5",
   "metadata": {},
   "source": [
    "# What is Tf-idf?\n",
    "\n",
    "Term frequency-inverse document frequency is a numerical statistic used to indicate how important a word is to each document in a collection of documents, or a corpus.\n",
    "\n",
    "When applying tf-idf to a corpus, each word is given a tf-idf score for each document, representing the relevance of that word to the particular document. A higher tf-idf score indicates a term is more important to the corresponding document.\n",
    "\n",
    "Tf-idf has many similarities with the bag-of-words language model, which if you recall is concerned with word count — how many times each word appears in a document.\n",
    "\n",
    "While tf-idf can be used in any situation bag-of-words can be used, there is a key difference in how it is calculated.\n",
    "\n",
    "Tf-idf relies on two different metrics in order to come up with an overall score:\n",
    "\n",
    "- term frequency, or how often a word appears in a document. This is the same as bag-of-words’ word count.\n",
    "- inverse document frequency, which is a measure of how often a word appears in the overall corpus. By penalizing the score of words that appear throughout a corpus, tf-idf can give better insight into how important a word is to a particular document of a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f99ce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       all you need be love  love be all you need  i love jelly and ice cream\n",
      "all                1.287682              1.287682                    0.000000\n",
      "and                0.000000              0.000000                    1.693147\n",
      "be                 1.287682              1.287682                    0.000000\n",
      "cream              0.000000              0.000000                    1.693147\n",
      "ice                0.000000              0.000000                    1.693147\n",
      "jelly              0.000000              0.000000                    1.693147\n",
      "love               1.000000              1.000000                    1.000000\n",
      "need               1.287682              1.287682                    0.000000\n",
      "you                1.287682              1.287682                    0.000000\n"
     ]
    }
   ],
   "source": [
    "from modules.preprocessing import preprocess_text\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# sample documents\n",
    "document_1 = \"All you need is love\"\n",
    "document_2 = \"Love is all you need\"\n",
    "document_3 = \"I love jelly and ice cream\"\n",
    "\n",
    "# corpus of documents\n",
    "corpus = [document_1, document_2, document_3]\n",
    "\n",
    "# preprocess documents\n",
    "processed_corpus = [preprocess_text(doc) for doc in corpus]\n",
    "\n",
    "# initialize and fit TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "tf_idf_scores = vectorizer.fit_transform(processed_corpus)\n",
    "\n",
    "# get vocabulary of terms\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "corpus_index = [n for n in processed_corpus]\n",
    "\n",
    "# create pandas DataFrame with tf-idf scores\n",
    "df_tf_idf = pd.DataFrame(tf_idf_scores.T.todense(), index=feature_names, columns=corpus_index)\n",
    "print(df_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede16fd4",
   "metadata": {},
   "source": [
    "# Breaking It Down Part I: Term Frequency\n",
    "\n",
    "The first component of tf-idf is term frequency, or how often a word appears in a document within the corpus.\n",
    "\n",
    "The value for the term frequency is the same as if applying the bag-of-words language model to a document. If you have previously studied bag-of-words, this will all be familiar! If not, have no fear.\n",
    "\n",
    "Term frequency indicates how often each word appears in the document. The intuition for including term frequency in the tf-idf calculation is that the more frequently a word appears in a single document, the more important that term is to the document.\n",
    "\n",
    "Consider the stanza from Emily Dickinson’s poem I’m Nobody! Who are you? below:\n",
    "\n",
    "``stanza = '''I'm nobody! Who are you?\n",
    "Are you nobody, too?\n",
    "Then there's a pair of us — don't tell!\n",
    "They'd banish us, you know.'''``\n",
    "\n",
    "The term frequency for “you” is 3, “nobody” is 2, “are” is 2, “us” is 2, and the rest of the terms have a frequency of 1. We can get a general sense of what this stanza is about by the most frequently used words.\n",
    "\n",
    "Term frequency can be calculated in Python using scikit-learn’s CountVectorizer, as shown below:\n",
    "\n",
    "``vectorizer = CountVectorizer()``\n",
    " \n",
    "``term_frequencies = vectorizer.fit_transform([stanza])``\n",
    "\n",
    "- A CountVectorizer object is initialized\n",
    "- The CountVectorizer object is fit (trained) and transformed (applied) on the corpus of data, returning the term frequencies for each term-document pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcdd9519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from modules.preprocessing import preprocess_text\n",
    "\n",
    "poem = '''\n",
    "Success is counted sweetest\n",
    "By those who ne'er succeed.\n",
    "To comprehend a nectar\n",
    "Requires sorest need.\n",
    "\n",
    "Not one of all the purple host\n",
    "Who took the flag to-day\n",
    "Can tell the definition,\n",
    "So clear, of victory,\n",
    "\n",
    "As he, defeated, dying,\n",
    "On whose forbidden ear\n",
    "The distant strains of triumph\n",
    "Break, agonized and clear!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ae1006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Term Frequency\n",
      "agonize                  1\n",
      "all                      1\n",
      "and                      1\n",
      "be                       1\n",
      "break                    1\n",
      "by                       1\n",
      "can                      1\n",
      "clear                    2\n",
      "comprehend               1\n",
      "count                    1\n",
      "day                      1\n",
      "defeat                   1\n",
      "definition               1\n",
      "die                      1\n",
      "distant                  1\n",
      "ear                      1\n",
      "er                       1\n",
      "flag                     1\n",
      "forbid                   1\n",
      "he                       1\n",
      "host                     1\n",
      "ne                       1\n",
      "nectar                   1\n",
      "need                     1\n",
      "not                      1\n",
      "of                       3\n",
      "on                       1\n",
      "one                      1\n",
      "purple                   1\n",
      "require                  1\n",
      "so                       1\n",
      "sorest                   1\n",
      "strain                   1\n",
      "succeed                  1\n",
      "success                  1\n",
      "sweet                    1\n",
      "take                     1\n",
      "tell                     1\n",
      "the                      4\n",
      "those                    1\n",
      "to                       2\n",
      "triumph                  1\n",
      "victory                  1\n",
      "who                      2\n",
      "whose                    1\n"
     ]
    }
   ],
   "source": [
    "# preprocess text\n",
    "processed_poem = preprocess_text(poem)\n",
    "\n",
    "# initialize and fit CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "term_frequencies = vectorizer.fit_transform([processed_poem])\n",
    "\n",
    "# get vocabulary of terms\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# create pandas DataFrame with term frequencies\n",
    "try:\n",
    "    df_term_frequencies = pd.DataFrame(term_frequencies.T.todense(), index=feature_names, columns=['Term Frequency'])\n",
    "    print(df_term_frequencies)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a094a",
   "metadata": {},
   "source": [
    "# Breaking It Down Part II: Inverse Document Frequency\n",
    "\n",
    "The inverse document frequency component of the tf-idf score penalizes terms that appear more frequently across a corpus. The intuition is that words that appear more frequently in the corpus give less insight into the topic or meaning of an individual document, and should thus be deprioritized.\n",
    "\n",
    "For example, terms like “the” or “go” are used all over the place, so in a bag-of-words model, they would be given priority even though they don’t provide much meaning; tf-idf would deprioritize these sorts of common words.\n",
    "\n",
    "We can calculate the inverse document frequency for some term t across a corpus using the below equation.\n",
    "\n",
    "$$\\log\\left(\\frac{\\textrm{Total number of documents}}{\\textrm{Number of documents with term } t}\\right)$$\n",
    "\n",
    "The important take away from the equation is that as the number of documents with the term t increases, the inverse document frequency decreases (due to the nature of the log function). The more frequently a term appears across the corpus, the less important it becomes to an individual document.\n",
    "\n",
    "Inverse document frequency can be calculated on a group of documents using scikit-learn’s TfidfTransformer:\n",
    "\n",
    "``transformer = TfidfTransformer(norm=None)\n",
    "transformer.fit(term_frequencies)\n",
    "inverse_doc_frequency = transformer.idf_``\n",
    "\n",
    "- a ``TfidfTransformer`` object is initialized. Don’t worry about the ``norm=None`` keyword argument for now, we will dig into this in the next exercise\n",
    "- the ``TfidfTransformer`` is fit (trained) on a term-document matrix of term frequencies\n",
    "- the ``.idf_`` attribute of the ``TfidfTransformer`` stores the inverse document frequencies of the terms as a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de3891a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from modules.term_frequency import term_frequencies, feature_names, df_term_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e430cff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Poem 1  Poem 2  Poem 3  Poem 4  Poem 5  Poem 6\n",
      "abash         0       0       0       0       1       0\n",
      "across        0       0       0       1       0       0\n",
      "admire        0       0       1       0       0       0\n",
      "again         0       0       0       1       0       0\n",
      "agonize       1       0       0       0       0       0\n",
      "...         ...     ...     ...     ...     ...     ...\n",
      "word          0       0       0       0       1       0\n",
      "wreck         0       0       0       1       0       0\n",
      "yet           0       0       0       0       1       0\n",
      "you           0       0       3       0       0       0\n",
      "your          0       0       1       0       0       0\n",
      "\n",
      "[173 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# display term-document matrix of term frequencies\n",
    "print(df_term_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73a63b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and fit TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "transformer.fit(term_frequencies)\n",
    "idf_values = transformer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2df5fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Inverse Document Frequency\n",
      "abash                      2.252763\n",
      "across                     2.252763\n",
      "admire                     2.252763\n",
      "again                      2.252763\n",
      "agonize                    2.252763\n",
      "...                             ...\n",
      "word                       2.252763\n",
      "wreck                      2.252763\n",
      "yet                        2.252763\n",
      "you                        2.252763\n",
      "your                       2.252763\n",
      "\n",
      "[173 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# create pandas DataFrame with inverse document frequencies\n",
    "try:\n",
    "    df_idf = pd.DataFrame(idf_values, index = feature_names, columns=['Inverse Document Frequency'])\n",
    "    print(df_idf)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd4db5",
   "metadata": {},
   "source": [
    "# Putting It All Together: Tf-idf\n",
    "\n",
    "Now that we understand how term frequency and inverse document frequency are calculated, let’s put it all together to calculate tf-idf!\n",
    "\n",
    "Tf-idf scores are calculated on a term-document basis. That means there is a tf-idf score for each word, for each document. The tf-idf score for some term t in a document d in some corpus is calculated as follows:\n",
    "\n",
    "$$\\texttt{tfidf}(t,d)=\\texttt{tf}(t,d) ∗ \\texttt{idf}(t,corpus)$$\n",
    "\n",
    "- ``tf(t,d)`` is the term frequency of term ``t`` in document ``d``\n",
    "- ``idf(t,corpus)`` is the inverse document frequency of a term ``t`` across ``corpus``\n",
    "\n",
    "We can easily calculate the tf-idf values for each term-document pair in our corpus using scikit-learn’s ``TfidfVectorizer``:\n",
    "\n",
    "``vectorizer = TfidfVectorizer(norm=None)\n",
    "tfidf_vectorizer = vectorizer.fit_transform(corpus)``\n",
    "\n",
    "- a ``TfidfVectorizer`` object is initialized. The ``norm=None`` keyword argument prevents scikit-learn from modifying the multiplication of term frequency and inverse document frequency\n",
    "- the ``TfidfVectorizer`` object is fit and transformed on the corpus of data, returning the tf-idf scores for each term-document pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d5eb88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from modules.term_frequency import term_frequencies, feature_names, df_term_frequencies\n",
    "from modules.poems import poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbafed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess documents\n",
    "processed_poems = [preprocess_text(poem) for poem in poems]\n",
    "\n",
    "# initialize and fit TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "tfidf_scores = vectorizer.fit_transform(processed_poems)\n",
    "\n",
    "# get vocabulary of terms\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# get corpus index\n",
    "corpus_index = [f\"Poem {i+1}\" for i in range(len(poems))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a645b61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Poem 1  Poem 2    Poem 3    Poem 4    Poem 5  Poem 6\n",
      "abash    0.000000     0.0  0.000000  0.000000  2.252763     0.0\n",
      "across   0.000000     0.0  0.000000  2.252763  0.000000     0.0\n",
      "admire   0.000000     0.0  2.252763  0.000000  0.000000     0.0\n",
      "again    0.000000     0.0  0.000000  2.252763  0.000000     0.0\n",
      "agonize  2.252763     0.0  0.000000  0.000000  0.000000     0.0\n",
      "...           ...     ...       ...       ...       ...     ...\n",
      "word     0.000000     0.0  0.000000  0.000000  2.252763     0.0\n",
      "wreck    0.000000     0.0  0.000000  2.252763  0.000000     0.0\n",
      "yet      0.000000     0.0  0.000000  0.000000  2.252763     0.0\n",
      "you      0.000000     0.0  6.758289  0.000000  0.000000     0.0\n",
      "your     0.000000     0.0  2.252763  0.000000  0.000000     0.0\n",
      "\n",
      "[173 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# create pandas DataFrame with tf-idf scores\n",
    "try:\n",
    "    df_tf_idf = pd.DataFrame(tfidf_scores.T.todense(), index=feature_names, columns=corpus_index)\n",
    "    print(df_tf_idf)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81be3f",
   "metadata": {},
   "source": [
    "# Converting Bag-of-Words to Tf-idf\n",
    "\n",
    "In addition to directly calculating the tf-idf scores for a set of terms across a corpus, you can also convert a bag-of-words model you have already created into tf-idf scores.\n",
    "\n",
    "Scikit-learn’s TfidfTransformer is up to the task of converting your bag-of-words model to tf-idf. You begin by initializing a TfidfTransformer object.\n",
    "\n",
    "``tf_idf_transformer = TfidfTransformer(norm=False)``\n",
    "\n",
    "Given a bag-of-words matrix ``count_matrix``, you can now multiply the term frequencies by their inverse document frequency to get the tf-idf scores as follows:\n",
    "\n",
    "``tf_idf_scores = tfidf_transformer.fit_transform(count_matrix)``\n",
    "\n",
    "This is very similar to how we calculated inverse document frequency, except this time we are fitting and transforming the TfidfTransformer to the term frequencies/bag-of-words vectors rather than just fitting the TfidfTransformer to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f920b41",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "Let’s recount all you have learned:\n",
    "\n",
    "- Term frequency-inverse document frequency, known as tf-idf, is a numerical statistic used to indicate how important a word is to each document in a collection of documents\n",
    "- tf-idf consists of two components, term frequency and inverse document frequency\n",
    "- term frequency is how often a word appears in a document. This is the same as bag-of-words’ word count\n",
    "- inverse document frequency is a measure of how often a word appears across all documents of a corpus\n",
    "- tf-idf is calculated as the term frequency multiplied by the inverse document frequency\n",
    "- term frequency, inverse document frequency, and tf-idf can be calculated in scikit-learn using the CountVectorizer, TfidfTransformer, and TfidfVectorizer objects, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989f22d",
   "metadata": {},
   "source": [
    "# Raven example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abc4c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from modules.raven import the_raven_stanzas\n",
    "from modules.preprocessing import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5e830a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Once upon a midnight dreary, while I pondered, weak and weary,\n",
      " Over many a quaint and curious volume of forgotten lore,\n",
      " While I nodded, nearly napping, suddenly there came a tapping,\n",
      " As of some one gently rapping, rapping at my chamber door\n"
     ]
    }
   ],
   "source": [
    "# view first stanza\n",
    "print(the_raven_stanzas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b764df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Stanza 1  Stanza 2  Stanza 3  Stanza 4  Stanza 5   Stanza 6  Stanza 7  \\\n",
      "above        0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "adore        0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "again        0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "agree        0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "ah           0.0       0.0  3.079442       0.0       0.0   0.000000       0.0   \n",
      "...          ...       ...       ...       ...       ...        ...       ...   \n",
      "wretch       0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "yet          0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "yore         0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "you          0.0       0.0  0.000000       0.0       0.0  10.454720       0.0   \n",
      "your         0.0       0.0  0.000000       0.0       0.0   3.484907       0.0   \n",
      "\n",
      "        Stanza 8  Stanza 9  Stanza 10  ...  Stanza 14  Stanza 15  Stanza 16  \\\n",
      "above   0.000000  4.772589        0.0  ...        0.0        0.0   0.000000   \n",
      "adore   0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "again   3.484907  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "agree   0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "ah      0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "...          ...       ...        ...  ...        ...        ...        ...   \n",
      "wretch  0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "yet     0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "yore    0.000000  3.079442        0.0  ...        0.0        0.0   6.158883   \n",
      "you     0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "your    0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "\n",
      "        Stanza 17  Stanza 18  Stanza 19  Stanza 20  Stanza 21  Stanza 22  \\\n",
      "above    0.000000   0.000000   0.000000   2.386294        0.0   2.386294   \n",
      "adore    0.000000   0.000000   0.000000   3.484907        0.0   0.000000   \n",
      "again    0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "agree    0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "ah       3.079442   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "wretch   0.000000   3.484907   0.000000   0.000000        0.0   0.000000   \n",
      "yet      0.000000   0.000000   3.079442   0.000000        0.0   0.000000   \n",
      "yore     0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "you      0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "your     0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "\n",
      "        Stanza 23  \n",
      "above    2.386294  \n",
      "adore    0.000000  \n",
      "again    0.000000  \n",
      "agree    0.000000  \n",
      "ah       0.000000  \n",
      "...           ...  \n",
      "wretch   0.000000  \n",
      "yet      0.000000  \n",
      "yore     0.000000  \n",
      "you      0.000000  \n",
      "your     0.000000  \n",
      "\n",
      "[413 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# preprocess documents\n",
    "processed_stanzas = [preprocess_text(stanza) for stanza in the_raven_stanzas]\n",
    "\n",
    "# initialize and fit TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "tfidf_scores = vectorizer.fit_transform(processed_stanzas)\n",
    "\n",
    "\n",
    "# get vocabulary of terms\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# get stanza index\n",
    "stanza_index = [f\"Stanza {i+1}\" for i in range(len(the_raven_stanzas))]\n",
    "\n",
    "# create pandas DataFrame with tf-idf scores\n",
    "try:\n",
    "    df_tf_idf = pd.DataFrame(tfidf_scores.T.todense(), index=feature_names, columns=stanza_index)\n",
    "    print(df_tf_idf)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b7efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f9cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c559a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
