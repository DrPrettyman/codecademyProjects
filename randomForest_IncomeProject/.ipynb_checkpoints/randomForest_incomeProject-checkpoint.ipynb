{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3defe1",
   "metadata": {},
   "source": [
    "# Predicting Income with Random Forests\n",
    "\n",
    "In this project, we will be using a dataset containing census information from UCI’s Machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/census%20income\n",
    "\n",
    "By using this census data with a random forest, we will try to predict whether or not a person makes more than $50,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37c1bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15502630",
   "metadata": {},
   "source": [
    "There’s a small problem with our data that is a little hard to catch — every string has an extra space at the start. For example, the first row’s native-country is \" United-States\", but we want it to be \"United-States\". This is happening because in income.csv there are spaces after the commas. To fix this, we can add the parameter delimiter = \", \" to our read_csv() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c70a5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = pd.read_csv('adult.data', delimiter = \", \",\n",
    "                          names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                                 'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                                 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                                 'income'],\n",
    "                         engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98422c00",
   "metadata": {},
   "source": [
    "Take a look at one of the rows of the data we’ve imported. **Print income_data.iloc[0]** to see the first row in its entirety. Did this person make more than $50,000? What is the name of the column that contains that information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a058583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                          39\n",
      "workclass             State-gov\n",
      "fnlwgt                    77516\n",
      "education             Bachelors\n",
      "education-num                13\n",
      "marital-status    Never-married\n",
      "occupation         Adm-clerical\n",
      "relationship      Not-in-family\n",
      "race                      White\n",
      "sex                        Male\n",
      "capital-gain               2174\n",
      "capital-loss                  0\n",
      "hours-per-week               40\n",
      "native-country    United-States\n",
      "income                    <=50K\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(income_data.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da5502f",
   "metadata": {},
   "source": [
    "Now that we have our data imported into a DataFrame, we can begin putting it in a format that our Random Forest can work with. To do this, we need to separate the labels from the rest of the data.\n",
    "\n",
    "For this project, the labels are in the column called \"income\". Create a variable named labels that contains only the column \"income\" from the income_data DataFrame.\n",
    "\n",
    "We’ll also want to pick which columns to use when trying to predict income. For now, let’s select \"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", and \"sex\". Create a new variable named data that contains only those columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf87139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = income_data['income']\n",
    "data = income_data[['age', 'capital-gain', 'capital-loss', 'hours-per-week', 'sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87858635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfe465fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        <=50K\n",
      "1        <=50K\n",
      "2        <=50K\n",
      "3        <=50K\n",
      "4        <=50K\n",
      "         ...  \n",
      "32556    <=50K\n",
      "32557     >50K\n",
      "32558    <=50K\n",
      "32559    <=50K\n",
      "32560     >50K\n",
      "Name: income, Length: 32561, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47819c18",
   "metadata": {},
   "source": [
    "Finally, we want to split our data and labels into a training set and a test set. We’ll use the training set to build the random forest, and the test set to see how accurate it is. Use the train_test_split() function to do this.\n",
    "\n",
    "train_test_split() returns four values — name them train_data, test_data, train_labels, and test_labels. When calling train_test_split(), it should take three arguments — data, labels and random_state = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "633053f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c8d949",
   "metadata": {},
   "source": [
    "We’re now ready to use this data to build and test our random forest. First, create a RandomForestClassifier and name it forest. When you create the random forest, use the parameter random_state = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d803df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abcd8eb",
   "metadata": {},
   "source": [
    "Next, we need to fit the model. We want to use the training data and training labels to train the random forest.\n",
    "\n",
    "Call forest‘s .fit() method using train_data and train_labels as parameters. When you run your code, there should be an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5837835",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Female'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-94c17d6bac58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             )\n\u001b[0;32m--> 304\u001b[0;31m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[1;32m    305\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Female'"
     ]
    }
   ],
   "source": [
    "forest.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16feab9",
   "metadata": {},
   "source": [
    "There **seems to be a problem** with using the column \"sex\" when training the random forest.\n",
    "\n",
    "In that column, there are values like \"Male\" and \"Female\". Random forests **can’t use columns that contain Strings** — they have to be continuous values like integers or floats.\n",
    "\n",
    "If we take every row and make every \"Male\" a 0 and every \"Female\" a 1, we could then use the column in our random forest. Before creating the data variable, use this line of code:\n",
    "\n",
    "$\\texttt{income_data[\"sex-int\"] = income_data[\"sex\"].apply(lambda row: 0 if row == \"Male\" else 1)}$\n",
    "\n",
    "This creates a new column called \"sex-int\" in the income_data DataFrame. Every row in that new column contains a 0 if the row’s \"sex\" column contained \"Male\" and a 1 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4438e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data[\"sex-int\"] = income_data[\"sex\"].apply(lambda row: 0 if row == \"Male\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6db6d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = income_data['income']\n",
    "data = income_data[['age', 'capital-gain', 'capital-loss', 'hours-per-week', 'sex-int']]\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state=1)\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "forest.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc421fe8",
   "metadata": {},
   "source": [
    "We can now test its accuracy. Call forest‘s .score() method using test_data and test_labels as parameters. Print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdfd7163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8272939442328953\n"
     ]
    }
   ],
   "source": [
    "print(forest.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c63a87",
   "metadata": {},
   "source": [
    "There are a couple of other columns that use strings that might be useful to use. Let’s try transforming the values in the \"native-country\" column.\n",
    "\n",
    "We should first take a look at the different values that exist in the column. Print income_data[\"native-country\"].value_counts().\n",
    "\n",
    "Since the majority of the data comes from \"United-States\", it might make sense to make a column where every row that contains \"United-States\" becomes a 0 and any other country becomes a 1. Use the syntax from creating the \"sex-int\" column to create a \"country-int\" column.\n",
    "\n",
    "When mapping Strings to numbers like this, it is important to make sure that continuous numbers make sense. For example, it wouldn’t make much sense to map \"United-States\" to 0, \"Germany\" to 1, and \"Mexico\" to 2. If we did this, we’re saying that Mexico is more similar to Germany than it is to the United States.\n",
    "\n",
    "However, if you had values in a column like \"low\", \"medium\", and \"high\" mapping those values to 0, 1, and 2 would make sense because their representation as Strings is also continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "629972f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(income_data[\"native-country\"].value_counts())\n",
    "\n",
    "income_data[\"country-int\"] = income_data[\"native-country\"].apply(lambda row: 0 if row == \"United-States\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e0d0eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = income_data['income']\n",
    "data = income_data[['age', 'capital-gain', 'capital-loss', 'hours-per-week', 'sex-int', 'country-int']]\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state=1)\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "forest.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a78fe22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8225033779633951\n"
     ]
    }
   ],
   "source": [
    "print(forest.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606766d3",
   "metadata": {},
   "source": [
    "Now that you’ve gotten the hang of transforming, adding, and removing columns from your training data, it’s time to explore on your own to try to make the best classifier possible.\n",
    "\n",
    "As you play around with the data, here are some ideas that you might want to try:\n",
    "\n",
    "Create a tree.DecisionTreeClassifier, train it, test is using the same data, and compare the results to the random forest. When does the random forest do better than the single tree? When does a single tree do just as well as the forest?\n",
    "After calling .fit() on the forest, print forest.feature_importances_. This will show you a list of numbers where each number corresponds to the relevance of a column from the training data. Which features tend to be more relevant?\n",
    "Use some of the other columns that use continuous variables, or transform columns that use strings!\n",
    "Code Editor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265d564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
